{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YCH4bZfXKjRl",
        "HLMdSrcDKnl1"
      ],
      "mount_file_id": "15OkD_T-5fjSeHZ_N95sADvwZ3li3xcSF",
      "authorship_tag": "ABX9TyNaG2FEodumCCsv6Vsb70Cj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KasMasVan/Codes-and-Notes-for-Some-Public-Coureses/blob/main/Zero_shot_CoT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare the files and packages"
      ],
      "metadata": {
        "id": "YCH4bZfXKjRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UMhGgeUZIdcp"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/github_repo\n",
        "# !git clone https://github.com/kojima-takeshi188/zero_shot_cot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/github_repo/zero_shot_cot/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkh7flZrJ2TR",
        "outputId": "a5881016-5946-46f9-8a61-80258d42e2a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/github_repo/zero_shot_cot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install openai tenacity backoff"
      ],
      "metadata": {
        "id": "p5ibZ95vKQ7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e194b4e-2d9e-434b-ec88-51ab6418d363"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.9/dist-packages (8.2.2)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.9/dist-packages (2.2.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (3.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "eUkijUrfLYgA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run by Script"
      ],
      "metadata": {
        "id": "HLMdSrcDKnl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --method=zero_shot_cot --model=codex --dataset=commonsensqa --limit_dataset_size=10 --api_time_interval=3.0 --cot_trigger_no=15"
      ],
      "metadata": {
        "id": "8uBDNU33KiFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run by Notebook"
      ],
      "metadata": {
        "id": "oPZ5KDktndLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparations: Packages and Functions"
      ],
      "metadata": {
        "id": "2yXED709nxy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import argparse\n",
        "import logging\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from utils import *\n",
        "\n",
        "def parse_arguments(args):\n",
        "    parser = argparse.ArgumentParser(description=\"Zero-shot-CoT\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--api_log_file_name\", type=str, default=None, help=\"mandatory argument ! json['i>=1']['j==1']['k={1,2}'][{'request', response'}]\"\n",
        "    )\n",
        "    \n",
        "    parser.add_argument(\"--random_seed\", type=int, default=1, help=\"random seed\")\n",
        "    \n",
        "    parser.add_argument(\n",
        "        \"--dataset\", type=str, default=\"aqua\", choices=[\"aqua\", \"gsm8k\", \"commonsensqa\", \"addsub\", \"multiarith\",  \"strategyqa\", \"svamp\", \"singleeq\", \"bigbench_date\", \"object_tracking\", \"coin_flip\", \"last_letters\"], help=\"dataset used for experiment\"\n",
        "    )\n",
        "    \n",
        "    # parser.add_argument(\"--minibatch_size\", type=int, default=1, choices=[1], help=\"minibatch size should be 1 because GPT-3 API takes only 1 input for each request\")\n",
        "    parser.add_argument(\"--minibatch_size\", type=int, default=1, help=\"Number of samples in each call to API.\")\n",
        "    \n",
        "    parser.add_argument(\"--max_num_worker\", type=int, default=3, help=\"maximum number of workers for dataloader\")\n",
        "    \n",
        "    parser.add_argument(\n",
        "        \"--model\", type=str, default=\"gpt3\", choices=[\"gpt3\", \"gpt3-medium\", \"gpt3-large\", \"gpt3-xl\", \"codex\"], help=\"model used for decoding. Note that 'gpt3' are the smallest models.\"\n",
        "    )\n",
        "    \n",
        "    parser.add_argument(\n",
        "        \"--method\", type=str, default=\"zero_shot_cot\", choices=[\"zero_shot\", \"zero_shot_cot\", \"few_shot\", \"few_shot_cot\"], help=\"method\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cot_trigger_no\", type=int, default=1, help=\"A trigger sentence that elicits a model to execute chain of thought\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_length_cot\", type=int, default=128, help=\"maximum length of output tokens by model for reasoning extraction\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_length_direct\", type=int, default=32, help=\"maximum length of output tokens by model for answer extraction\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--limit_dataset_size\", type=int, default=10, help=\"whether to limit test dataset size. if 0, the dataset size is unlimited and we use all the samples in the dataset for testing.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--api_time_interval\", type=float, default=1.0, help=\"\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log_dir\", type=str, default=\"./log/\", help=\"log directory\"\n",
        "    )\n",
        "    args = parser.parse_args(args=args)\n",
        "    \n",
        "    if args.dataset == \"aqua\":\n",
        "        args.dataset_path = \"./dataset/AQuA/test.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, among A through E, the answer is\"\n",
        "    elif args.dataset == \"gsm8k\":\n",
        "        args.dataset_path = \"./dataset/grade-school-math/test.jsonl\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (arabic numerals) is\"\n",
        "    elif args.dataset == \"commonsensqa\":\n",
        "        args.dataset_path = \"./dataset/CommonsenseQA/dev_rand_split.jsonl\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, among A through E, the answer is\"\n",
        "        args.plausible_answer_trigger = \"Choose the most plausible answer from among choices A through E.\"\n",
        "    elif args.dataset == \"addsub\":\n",
        "        args.dataset_path = \"./dataset/AddSub/AddSub.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (arabic numerals) is\"\n",
        "    elif args.dataset == \"multiarith\":\n",
        "        args.dataset_path = \"./dataset/MultiArith/MultiArith.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (arabic numerals) is\"\n",
        "    elif args.dataset == \"strategyqa\":\n",
        "        args.dataset_path = \"./dataset/StrategyQA/task.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (Yes or No) is\"\n",
        "    elif args.dataset == \"svamp\":\n",
        "        args.dataset_path = \"./dataset/SVAMP/SVAMP.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (arabic numerals) is\"\n",
        "    elif args.dataset == \"singleeq\":\n",
        "        args.dataset_path = \"./dataset/SingleEq/questions.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (arabic numerals) is\"\n",
        "    elif args.dataset == \"bigbench_date\":\n",
        "        args.dataset_path = \"./dataset/Bigbench_Date/task.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, among A through F, the answer is\"\n",
        "    elif args.dataset == \"object_tracking\":\n",
        "        args.dataset_path = \"./dataset/Bigbench_object_tracking/task.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, among A through C, the answer is\"\n",
        "    elif args.dataset == \"coin_flip\":\n",
        "        args.dataset_path = \"./dataset/coin_flip/coin_flip.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer (Yes or No) is\"\n",
        "    elif args.dataset == \"last_letters\":\n",
        "        args.dataset_path = \"./dataset/last_letters/last_letters.json\"\n",
        "        args.direct_answer_trigger = \"\\nTherefore, the answer is\"\n",
        "    else:\n",
        "        raise ValueError(\"dataset is not properly defined ...\")\n",
        "        \n",
        "    # \"Therefore, the answer ...\" -> \"The answer ...\"\n",
        "    trigger = args.direct_answer_trigger.replace(\"\\nTherefore, \", \"\")\n",
        "    args.direct_answer_trigger_for_zeroshot = trigger[0].upper() + trigger[1:]\n",
        "    args.direct_answer_trigger_for_zeroshot_cot = args.direct_answer_trigger\n",
        "    \n",
        "    args.direct_answer_trigger_for_fewshot = \"The answer is\"\n",
        "    \n",
        "    if args.cot_trigger_no == 1:\n",
        "        args.cot_trigger = \"Let's think step by step.\"\n",
        "    elif args.cot_trigger_no == 2:\n",
        "        args.cot_trigger = \"We should think about this step by step.\"\n",
        "    elif args.cot_trigger_no == 3:\n",
        "        args.cot_trigger = \"First,\"\n",
        "    elif args.cot_trigger_no == 4:\n",
        "        args.cot_trigger = \"Before we dive into the answer,\"\n",
        "    elif args.cot_trigger_no == 5:\n",
        "        args.cot_trigger = \"Proof followed by the answer.\"\n",
        "    elif args.cot_trigger_no == 6:\n",
        "        args.cot_trigger = \"Let's think step by step in a realistic way.\"\n",
        "    elif args.cot_trigger_no == 7:\n",
        "        args.cot_trigger = \"Let's think step by step using common sense and knowledge.\"\n",
        "    elif args.cot_trigger_no == 8:\n",
        "        args.cot_trigger = \"Let's think like a detective step by step.\"\n",
        "    elif args.cot_trigger_no == 9:\n",
        "        args.cot_trigger = \"Let's think about this logically.\"\n",
        "    elif args.cot_trigger_no == 10:\n",
        "        args.cot_trigger = \"Let's think step by step. First,\"\n",
        "    elif args.cot_trigger_no == 11:\n",
        "        args.cot_trigger = \"Let's think\"\n",
        "    elif args.cot_trigger_no == 12:\n",
        "        args.cot_trigger = \"Let's solve this problem by splitting it into steps.\"\n",
        "    elif args.cot_trigger_no == 13:\n",
        "        args.cot_trigger = \"The answer is after the proof.\"\n",
        "    elif args.cot_trigger_no == 14:\n",
        "        args.cot_trigger = \"Let's be realistic and think step by step.\"\n",
        "    elif args.cot_trigger_no == 15:\n",
        "        args.cot_trigger = \"Let's check them one by one.\"\n",
        "    else:\n",
        "        raise ValueError(\"cot_trigger_no is not properly defined ...\")\n",
        "    \n",
        "    return args\n",
        "\n",
        "def main(args):\n",
        "    # args = parse_arguments()\n",
        "    print('*****************************')\n",
        "    print(args)\n",
        "    print('*****************************')\n",
        "    \n",
        "    fix_seed(args.random_seed)\n",
        "    \n",
        "    print(\"OPENAI_API_KEY:\")\n",
        "    print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "    \n",
        "    # Initialize decoder class (load model and tokenizer) ...\n",
        "    decoder = Decoder(args)\n",
        "    \n",
        "    print(\"setup data loader ...\")\n",
        "    dataloader = setup_data_loader(args)\n",
        "    print_now()\n",
        "    \n",
        "    if args.method == \"few_shot\":\n",
        "        demo = create_demo_text(args, cot_flag=False)\n",
        "    elif args.method == \"few_shot_cot\":\n",
        "        demo = create_demo_text(args, cot_flag=True)\n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "    total = 0\n",
        "    correct_list = []        \n",
        "    for i, data in enumerate(dataloader):\n",
        "        print('*************************')\n",
        "        print(\"{}st data\".format(i+1))\n",
        "                \n",
        "        # Prepare question template ...\n",
        "        x, y = data\n",
        "        x = \"Q: \" + x[0] + \"\\n\" + \"A:\"\n",
        "        y = y[0].strip()\n",
        "        \n",
        "        if args.method == \"zero_shot\":\n",
        "            x = x + \" \" + args.direct_answer_trigger_for_zeroshot\n",
        "        elif args.method == \"zero_shot_cot\":\n",
        "            x = x + \" \" + args.cot_trigger\n",
        "        elif args.method == \"few_shot\":\n",
        "            x = demo + x\n",
        "        elif args.method == \"few_shot_cot\":\n",
        "            x = demo + x\n",
        "        else:\n",
        "            raise ValueError(\"method is not properly defined ...\")\n",
        "        \n",
        "        # Answer prediction by generating text ...\n",
        "        max_length = args.max_length_cot if \"cot\" in args.method else args.max_length_direct\n",
        "        z = decoder.decode(args, x, max_length, i, 1)[0]\n",
        "\n",
        "        # Answer extraction for zero-shot-cot ...\n",
        "        if args.method == \"zero_shot_cot\":\n",
        "            z2 = x + z + \" \" + args.direct_answer_trigger_for_zeroshot_cot\n",
        "            max_length = args.max_length_direct\n",
        "            pred = decoder.decode(args, z2, max_length, i, 2)[0]\n",
        "            print(z2 + pred)\n",
        "        else:\n",
        "            pred = z\n",
        "            print(x + pred)\n",
        "\n",
        "        # Clensing of predicted answer ...\n",
        "        pred = answer_cleansing(args, pred)\n",
        "        \n",
        "        # Choose the most frequent answer from the list ...\n",
        "        print(\"pred : {}\".format(pred))\n",
        "        print(\"GT : \" + y)\n",
        "        print('*************************')\n",
        "        \n",
        "        # Checking answer ...\n",
        "        correct = (np.array([pred]) == np.array([y])).sum().item()\n",
        "        correct_list.append(correct)\n",
        "        total += 1 #np.array([y]).size(0)\n",
        "        \n",
        "        if (args.limit_dataset_size != 0) and ((i+1) >= args.limit_dataset_size):\n",
        "            break\n",
        "            #raise ValueError(\"Stop !!\")\n",
        "    \n",
        "    # Calculate accuracy ...\n",
        "    accuracy = (sum(correct_list) * 1.0 / total) * 100\n",
        "    print(\"accuracy : {}\".format(accuracy))"
      ],
      "metadata": {
        "id": "ZT26j3pnoI1F"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_fun(args):\n",
        "  # args = parse_arguments()\n",
        "  print('*****************************')\n",
        "  print(args)\n",
        "  print('*****************************')\n",
        "  \n",
        "  fix_seed(args.random_seed)\n",
        "  \n",
        "  print(\"OPENAI_API_KEY:\")\n",
        "  print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "  \n",
        "  # Initialize decoder class (load model and tokenizer) ...\n",
        "  decoder = Decoder(args)\n",
        "  \n",
        "  print(\"setup data loader ...\")\n",
        "  dataloader = setup_data_loader(args)\n",
        "  print_now()\n",
        "  \n",
        "  if args.method == \"few_shot\":\n",
        "    demo = create_demo_text(args, cot_flag=False)\n",
        "  elif args.method == \"few_shot_cot\":\n",
        "    demo = create_demo_text(args, cot_flag=True)\n",
        "  else:\n",
        "    pass\n",
        "  \n",
        "  total = 0\n",
        "  correct_list = []        \n",
        "  for i, data in enumerate(dataloader):         \n",
        "\n",
        "    print('*************************')\n",
        "    print(f\"{i * args.minibatch_size, (i+1) * args.minibatch_size - 1}th data\")\n",
        "    # Prepare question template ...\n",
        "    x, y = data\n",
        "    # x = \"Q: \" + x[0] + \"\\n\" + \"A:\"\n",
        "    # y = y[0].strip()\n",
        "    x = [\"Q: \" + prompt + \"\\n\" + \"A:\" for prompt in x]\n",
        "    y = [item.strip() for item in y]\n",
        "      \n",
        "    if args.method == \"zero_shot\":\n",
        "      # x = x + \" \" + args.direct_answer_trigger_for_zeroshot\n",
        "      x = [prompt + \" \" + args.direct_answer_trigger_for_zeroshot for prompt in x]\n",
        "    elif args.method == \"zero_shot_cot\":\n",
        "      # x = x + \" \" + args.cot_trigger\n",
        "      x = [prompt + \" \" + args.cot_trigger for prompt in x]\n",
        "    elif args.method == \"few_shot\":\n",
        "      # x = demo + x\n",
        "      x = [demo + prompt for prompt in x]\n",
        "    elif args.method == \"few_shot_cot\":\n",
        "      # x = demo + x\n",
        "      x = [demo + prompt for prompt in x]\n",
        "    else:\n",
        "      raise ValueError(\"method is not properly defined ...\")\n",
        "    \n",
        "      \n",
        "    # Answer prediction by generating text ...\n",
        "    max_length = args.max_length_cot if \"cot\" in args.method else args.max_length_direct\n",
        "    z = decoder.decode(args, x, max_length, i, 1)\n",
        "\n",
        "    # Answer extraction for zero-shot-cot ...\n",
        "    if args.method == \"zero_shot_cot\":\n",
        "      # z2 = x + z + \" \" + args.direct_answer_trigger_for_zeroshot_cot\n",
        "      z2 = [prompt + output + \" \" + args.direct_answer_trigger_for_zeroshot_cot for prompt, output in zip(x, z)]\n",
        "      max_length = args.max_length_direct\n",
        "      pred = decoder.decode(args, z2, max_length, i, 2)\n",
        "      # print(z2 + pred)\n",
        "      print([first + second for first, second in zip(z2, pred)])\n",
        "    else:\n",
        "      pred = z\n",
        "      # print(x + pred)\n",
        "      print([prompt + output for prompt, output in zip(x, pred)])\n",
        "    \n",
        "\n",
        "    # Clensing of predicted answer ...\n",
        "    # pred = answer_cleansing(args, pred)\n",
        "    pred = [answer_cleansing(args, output) for output in pred]\n",
        "    \n",
        "    # Choose the most frequent answer from the list ...\n",
        "    print(\"pred : {}\".format(pred))\n",
        "    # print(\"GT : \" + y)\n",
        "    print(\"GT : \" + str(y))\n",
        "    print('*************************')\n",
        "    \n",
        "    # Checking answer ...\n",
        "    # correct = (np.array([pred]) == np.array([y])).sum().item()\n",
        "    correct = (np.array(pred) == np.array(y)).sum().item()\n",
        "    correct_list.append(correct)\n",
        "    # total += 1 #np.array([y]).size(0)\n",
        "    total += len(y)\n",
        "    \n",
        "    if (args.limit_dataset_size != 0) and ((i+1) * args.minibatch_size >= args.limit_dataset_size):\n",
        "      break\n",
        "      #raise ValueError(\"Stop !!\")\n",
        "  \n",
        "  # Calculate accuracy ...\n",
        "  accuracy = (sum(correct_list) * 1.0 / total) * 100\n",
        "  print(\"accuracy : {}\".format(accuracy))"
      ],
      "metadata": {
        "id": "URNPQu91a2I9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arguments\n",
        "\n",
        "method = \"zero_shot_cot\" #@param [\"zero_shot\", \"zero_shot_cot\", \"few_shot\", \"few_shot_cot\"]\n",
        "model = \"gpt3\" #@param [\"gpt3\", \"gpt3-medium\", \"gpt3-large\", \"gpt3-xl\", \"codex\"]\n",
        "dataset = \"commonsensqa\" #@param [\"aqua\", \"gsm8k\", \"commonsensqa\", \"addsub\", \"multiarith\",  \"strategyqa\", \"svamp\", \"singleeq\", \"bigbench_date\", \"object_tracking\", \"coin_flip\", \"last_letters\"]\n",
        "limit_dataset_size = 5 #@param {type:\"integer\"}\n",
        "cot_trigger_no = 1 #@param {type:\"integer\"}\n",
        "minibatch_size = 1 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#list of strings\n",
        "arguments =[\n",
        "    f\"--method={method}\",\n",
        "    f\"--model={model}\",\n",
        "    f\"--dataset={dataset}\",\n",
        "    f\"--limit_dataset_size={limit_dataset_size}\",\n",
        "    f\"--cot_trigger_no={cot_trigger_no}\",\n",
        "    f\"--minibatch_size={minibatch_size}\",\n",
        "]\n",
        "args = parse_arguments(arguments)\n",
        "# main(args) # this only supports no batching\n",
        "main_fun(args) #this support both batching and no batching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeDb8-ztsEIE",
        "outputId": "0701cbbc-c917-47df-a7b1-a06eba29aebb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "Namespace(api_log_file_name=None, random_seed=1, dataset='commonsensqa', minibatch_size=1, max_num_worker=3, model='gpt3-xl', method='zero_shot_cot', cot_trigger_no=1, max_length_cot=128, max_length_direct=32, limit_dataset_size=5, api_time_interval=3.0, log_dir='./log/', dataset_path='./dataset/CommonsenseQA/dev_rand_split.jsonl', direct_answer_trigger='\\nTherefore, among A through E, the answer is', plausible_answer_trigger='Choose the most plausible answer from among choices A through E.', direct_answer_trigger_for_zeroshot='Among A through E, the answer is', direct_answer_trigger_for_zeroshot_cot='\\nTherefore, among A through E, the answer is', direct_answer_trigger_for_fewshot='The answer is', cot_trigger=\"Let's think step by step.\")\n",
            "*****************************\n",
            "OPENAI_API_KEY:\n",
            "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\n",
            "2023/03/11 12:20:25\n",
            "setup data loader ...\n",
            "worker_seed : 1\n",
            "dataloader_num_workers: 2\n",
            "dataset : commonsensqa\n",
            "data size : 1221\n",
            "average num of words for each sample : 27.75184275184275\n",
            "2023/03/11 12:20:25\n",
            "*************************\n",
            "(0, 0)th data\n",
            "[\"Q: What are candles good for eliminating? Answer Choices: (A) shelf (B) board (C) church (D) table (E) dark\\nA: Let's think step by step. Candles are often used for light, so (E) dark is probably not the answer. Candles are also used for decoration or to make a place smell nice, so (A) shelf, (B) board, (C) church, and (D) table are all possible answers. \\nTherefore, among A through E, the answer is probably (A), (B), (C), or (D).\"]\n",
            "pred_before :  probably (A), (B), (C), or (D).\n",
            "pred_after : A\n",
            "pred : ['A']\n",
            "GT : ['E']\n",
            "*************************\n",
            "*************************\n",
            "(1, 1)th data\n",
            "[\"Q: If there is a pond with trees around it, where it it likely located? Answer Choices: (A) ground (B) bathroom (C) forest (D) countryside (E) rural area\\nA: Let's think step by step. A pond is likely to be located near trees because trees need water to survive. Therefore, the most likely location for a pond with trees around it is in a forest. \\nTherefore, among A through E, the answer is C.\"]\n",
            "pred_before :  C.\n",
            "pred_after : C\n",
            "pred : ['C']\n",
            "GT : ['C']\n",
            "*************************\n",
            "*************************\n",
            "(2, 2)th data\n",
            "['Q: Reading newspaper one of many ways to practice your what? Answer Choices: (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank\\nA: Let\\'s think step by step. The first word is \"reading.\" This narrows down our choices to A and B. The second word is \"newspaper.\" This points us more towards A, because option B doesn\\'t make much sense. The last word is \"practice.\" This means that the answer is probably A, because option B is more of a skill than something you practice. \\nTherefore, among A through E, the answer is A.']\n",
            "pred_before :  A.\n",
            "pred_after : A\n",
            "pred : ['A']\n",
            "GT : ['A']\n",
            "*************************\n",
            "*************************\n",
            "(3, 3)th data\n",
            "[\"Q: What happens when to ice when it is in the sun? Answer Choices: (A) carved (B) melted (C) ice cream (D) antarctica (E) sculptured\\nA: Let's think step by step. Ice is in the sun. What does the sun do? It melts things, so (B) melted is the correct answer. \\nTherefore, among A through E, the answer is (B).\"]\n",
            "pred_before :  (B).\n",
            "pred_after : B\n",
            "pred : ['B']\n",
            "GT : ['B']\n",
            "*************************\n",
            "*************************\n",
            "(4, 4)th data\n",
            "[\"Q: James loved to surf but he wasn't good at it. He would always do what? Answer Choices: (A) wipe out (B) enjoy yourself (C) start fighting (D) get wet (E) drown\\nA: Let's think step by step. \\n\\nJames loved to surf. This is the given information. \\n\\nJames wasn't good at it. This is also given information. \\n\\nBecause James wasn't good at surfing, he would always wipe out. \\n\\nOption A, wipe out, is the correct answer. \\nTherefore, among A through E, the answer is A.\"]\n",
            "pred_before :  A.\n",
            "pred_after : A\n",
            "pred : ['A']\n",
            "GT : ['A']\n",
            "*************************\n",
            "accuracy : 80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70G-JbdEr2KT",
        "outputId": "3e6f9643-1068-43c4-d7b6-fdc6d8c6dff7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "Namespace(api_log_file_name=None, random_seed=1, dataset='commonsensqa', minibatch_size=1, max_num_worker=3, model='gpt3-xl', method='zero_shot_cot', cot_trigger_no=1, max_length_cot=128, max_length_direct=32, limit_dataset_size=5, api_time_interval=3.0, log_dir='./log/', dataset_path='./dataset/CommonsenseQA/dev_rand_split.jsonl', direct_answer_trigger='\\nTherefore, among A through E, the answer is', plausible_answer_trigger='Choose the most plausible answer from among choices A through E.', direct_answer_trigger_for_zeroshot='Among A through E, the answer is', direct_answer_trigger_for_zeroshot_cot='\\nTherefore, among A through E, the answer is', direct_answer_trigger_for_fewshot='The answer is', cot_trigger=\"Let's think step by step.\")\n",
            "*****************************\n",
            "OPENAI_API_KEY:\n",
            "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\n",
            "2023/03/11 12:22:18\n",
            "setup data loader ...\n",
            "worker_seed : 1\n",
            "dataloader_num_workers: 2\n",
            "dataset : commonsensqa\n",
            "data size : 1221\n",
            "average num of words for each sample : 27.75184275184275\n",
            "2023/03/11 12:22:18\n",
            "*************************\n",
            "1st data\n",
            "Q: What are candles good for eliminating? Answer Choices: (A) shelf (B) board (C) church (D) table (E) dark\n",
            "A: Let's think step by step. Candles are often used for light, so (E) dark is probably not the answer. Candles are also used for decoration or to make a place smell nice, so (A) shelf, (B) board, (C) church, and (D) table are all possible answers. \n",
            "Therefore, among A through E, the answer is probably (A), (B), (C), or (D).\n",
            "pred_before :  probably (A), (B), (C), or (D).\n",
            "pred_after : A\n",
            "pred : A\n",
            "GT : E\n",
            "*************************\n",
            "*************************\n",
            "2st data\n",
            "Q: If there is a pond with trees around it, where it it likely located? Answer Choices: (A) ground (B) bathroom (C) forest (D) countryside (E) rural area\n",
            "A: Let's think step by step. A pond is likely to be located near trees because trees need water to survive. Therefore, the most likely location for a pond with trees around it is in a forest. \n",
            "Therefore, among A through E, the answer is C.\n",
            "pred_before :  C.\n",
            "pred_after : C\n",
            "pred : C\n",
            "GT : C\n",
            "*************************\n",
            "*************************\n",
            "3st data\n",
            "Q: Reading newspaper one of many ways to practice your what? Answer Choices: (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank\n",
            "A: Let's think step by step. The first word is \"reading.\" This narrows down our choices to A and B. The second word is \"newspaper.\" This points us more towards A, because option B doesn't make much sense. The last word is \"practice.\" This means that the answer is probably A, because option B is more of a skill than something you practice. \n",
            "Therefore, among A through E, the answer is A.\n",
            "pred_before :  A.\n",
            "pred_after : A\n",
            "pred : A\n",
            "GT : A\n",
            "*************************\n",
            "*************************\n",
            "4st data\n",
            "Q: What happens when to ice when it is in the sun? Answer Choices: (A) carved (B) melted (C) ice cream (D) antarctica (E) sculptured\n",
            "A: Let's think step by step. Ice is in the sun. What does the sun do? It melts things, right? So if the sun melts things, and ice is in the sun, then the sun will melt the ice. \n",
            "Therefore, among A through E, the answer is B, melted.\n",
            "pred_before :  B, melted.\n",
            "pred_after : B\n",
            "pred : B\n",
            "GT : B\n",
            "*************************\n",
            "*************************\n",
            "5st data\n",
            "Q: James loved to surf but he wasn't good at it. He would always do what? Answer Choices: (A) wipe out (B) enjoy yourself (C) start fighting (D) get wet (E) drown\n",
            "A: Let's think step by step. \n",
            "\n",
            "James loved to surf. This is the given information. \n",
            "\n",
            "James wasn't good at it. This is also given information. \n",
            "\n",
            "Because James wasn't good at surfing, he would always wipe out. \n",
            "\n",
            "Option A, wipe out, is the correct answer. \n",
            "Therefore, among A through E, the answer is A.\n",
            "pred_before :  A.\n",
            "pred_after : A\n",
            "pred : A\n",
            "GT : A\n",
            "*************************\n",
            "accuracy : 80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Code in Notebook"
      ],
      "metadata": {
        "id": "bElqlvH5oRYr"
      }
    }
  ]
}